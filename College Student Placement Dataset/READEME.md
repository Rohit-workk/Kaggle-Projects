# College Student Placement Dataset - Project Overview and Approach

---

## üìÇ Dataset  
Dataset source: [College Student Placement - Kaggle](https://www.kaggle.com/datasets/vrajesh0sharma7/college-student-placement)  
- Samples: 10,000  
- Features: 10 (academic, skill, and extracurricular attributes)  
- Target variable: `Placement` (binary classification indicating if student is placed)

---

## üîç Data Understanding  
- Dataset contains academic scores (IQ, PrevSemResult, CGPA), academic performance ratings, internship experience, extracurricular scores, communication skills, projects completed, and college IDs.  
- Data is clean with no missing values.  
- Mixed feature types: numerical, ordinal, and categorical.

---

## ‚öôÔ∏è Exploratory Data Analysis  
- Descriptive statistics reveal wide variation in academic and skill scores.  
- Distribution plots and count plots show class imbalance with majority students not placed (83.4%).  
- Placement distribution varies by colleges, academic scores, and skill ratings.  
- Visualization of feature distributions shows higher placement rates in students with stronger communication skills, CGPA, and previous semester results.

---

## üß© Feature Engineering  
- Label encoded categorical features like CollegeID, InternshipExperience, and Placement for modeling.  
- Encoded CollegeID suits tree-based models as they handle categorical splits without ordinal assumptions.  
- Correlation analysis identifies features most related to placement, with top correlations:
  - CommunicationSkills (0.323)  
  - CGPA (0.322)  
  - PrevSemResult (0.318)  
  - IQ (0.286)  
  - ProjectsCompleted (0.217)  

---

## üß† Modeling  
- Prepared train-test split (80-20) and scaled numerical features.  
- Trained multiple classifiers including Logistic Regression, KNN, SVM, Decision Tree, Random Forest, Gradient Boosting, AdaBoost, Bagging, and Voting Classifier.  
- Tree-based models (Decision Tree, Random Forest, Gradient Boosting, AdaBoost, Bagging) achieved perfect accuracy scores (1.0), illustrating their strength on this dataset.  
- Logistic Regression, KNN, and SVM achieved high but slightly lower accuracy (around 90%).  
- Label encoding of CollegeID beneficial for tree models; potential bias for linear/distance models minimal in this case.

---

## üìä Key Insights  
- Communication skills, CGPA, and past semester performance are the strongest predictors of placement.  
- Extracurricular engagement and completed projects also contribute positively.  
- College-specific information, represented through CollegeID, can be leveraged effectively by tree methods to capture institutional effects.  
- Ensemble and boosting methods offer robust and perfect classification on this synthetic dataset.

---

## üîÆ Future Work  
- Experiment with other encoding schemes for CollegeID (e.g., target or one-hot encoding) to enhance model generalization on linear models.  
- Evaluate model robustness on real-world imbalanced placement datasets.  
- Incorporate feature selection and dimensionality reduction for web deployment.  
- Explore explainability methods to provide actionable student placement insights.

---

## üìå Usage  
- Analysis and modeling performed with Python libraries including pandas, scikit-learn, matplotlib, seaborn.  
- Suitable for Kaggle notebook or local Jupyter environment setups.

---
